import { Composer } from 'telegraf'
import { MyContext } from './interfaces'
import { imageModelMenu } from './menu/imageModelMenu'

import { balanceCommand } from './commands/balanceCommand'
import { menuCommand } from './commands/menuCommand'
import { generateTextToImage } from './services/generateTextToImage'
import { isRussian } from './helpers/language'

import { generateNeuroImage } from './services/generateNeuroImage'

import { handleSizeSelection } from './handlers'
import { imageModelPrices } from './price/models'
import { mainMenu } from './menu'

const myComposer = new Composer<MyContext>()

myComposer.hears(['ðŸ§  ÐœÐ¾Ð·Ð³ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°', 'ðŸ§  Avatar Brain'], async ctx => {
  console.log('CASE: Ð¡Ð¾Ð·Ð´Ð°Ñ‚ÑŒ Ð°Ð²Ð°Ñ‚Ð°Ñ€')
  ctx.session.mode = 'avatar'

  await ctx.scene.enter('avatarWizard')
})

myComposer.hears(['Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ', 'Help for the command'], async ctx => {
  console.log('CASE: Ð¡Ð¿Ñ€Ð°Ð²ÐºÐ° Ð¿Ð¾ ÐºÐ¾Ð¼Ð°Ð½Ð´Ðµ')
  await ctx.scene.enter('helpCommand')
})

myComposer.hears(['ðŸŒŸ Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð˜Ð˜', 'ðŸŒŸ Select AI Model'], async ctx => {
  console.log('CASE: Ð’Ñ‹Ð±Ð¾Ñ€ Ð¼Ð¾Ð´ÐµÐ»Ð¸ Ð˜Ð˜')
  ctx.session.mode = 'select_model'
  await ctx.scene.enter('selectModelWizard')
})

myComposer.hears(
  ['ðŸ¤– Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ðµ Ñ‚ÐµÐ»Ð¾ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°', 'ðŸ¤– Digital Avatar Body'],
  async ctx => {
    console.log('CASE: Ð¦Ð¸Ñ„Ñ€Ð¾Ð²Ð¾Ðµ Ñ‚ÐµÐ»Ð¾ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°')
    ctx.session.mode = 'digital_avatar_body'
    await ctx.scene.enter('digitalAvatarBodyWizard')
  }
)

myComposer.hears(['ðŸ“¸ ÐÐµÐ¹Ñ€Ð¾Ñ„Ð¾Ñ‚Ð¾', 'ðŸ“¸ NeuroPhoto'], async ctx => {
  console.log('CASE: ÐÐµÐ¹Ñ€Ð¾Ñ„Ð¾Ñ‚Ð¾')
  ctx.session.mode = 'neuro_photo'
  await ctx.scene.enter('neuroPhotoWizard')
})

myComposer.hears(['ðŸŽ¥ Ð’Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°', 'ðŸŽ¥ Text to Video'], async ctx => {
  console.log('CASE: Ð’Ð¸Ð´ÐµÐ¾ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°')
  ctx.session.mode = 'text_to_video'
  await ctx.scene.enter('textToVideoWizard')
})

myComposer.hears(['ðŸŽ™ï¸ Ð¢ÐµÐºÑÑ‚ Ð² Ð³Ð¾Ð»Ð¾Ñ', 'ðŸŽ™ï¸ Text to Voice'], async ctx => {
  console.log('CASE: Ð¢ÐµÐºÑÑ‚ Ð² Ð³Ð¾Ð»Ð¾Ñ')
  ctx.session.mode = 'text_to_speech'
  await ctx.scene.enter('textToSpeechWizard')
})

myComposer.hears(['ðŸŽ¤ Ð“Ð¾Ð»Ð¾Ñ Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°', 'ðŸŽ¤ Voice for Avatar'], async ctx => {
  console.log('CASE: Ð“Ð¾Ð»Ð¾Ñ Ð´Ð»Ñ Ð°Ð²Ð°Ñ‚Ð°Ñ€Ð°')
  ctx.session.mode = 'voice'
  await ctx.scene.enter('voiceAvatarWizard')
})

myComposer.hears(
  ['ðŸ–¼ï¸ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°', 'ðŸ–¼ï¸ Text to Image'],
  async ctx => {
    console.log('CASE: Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°')
    ctx.session.mode = 'text_to_image'
    await ctx.scene.enter('textToImageWizard')
    // await imageModelMenu(ctx)
  }
)

myComposer.hears(
  ['ðŸ” ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ', 'ðŸ” Image to Prompt'],
  async ctx => {
    console.log('CASE: ÐžÐ¿Ð¸ÑÐ°Ð½Ð¸Ðµ Ð¸Ð· Ð¸Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ñ')
    ctx.session.mode = 'image_to_prompt'
    await ctx.scene.enter('imageToPromptWizard')
  }
)

myComposer.hears(['ðŸ‘¥ ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð°', 'ðŸ‘¥ Invite a friend'], async ctx => {
  console.log('CASE: ÐŸÑ€Ð¸Ð³Ð»Ð°ÑÐ¸Ñ‚ÑŒ Ð´Ñ€ÑƒÐ³Ð°')
  ctx.session.mode = 'invite'
  await ctx.scene.enter('inviteCommand')
})

myComposer.hears(['â“ ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ', 'â“ Help'], async ctx => {
  console.log('CASE: ÐŸÐ¾Ð¼Ð¾Ñ‰ÑŒ')
  ctx.session.mode = 'help'
  await ctx.scene.enter('neuroQuestCommand')
})

myComposer.hears(['ðŸŽ® ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ', 'ðŸŽ® Start learning'], async ctx => {
  console.log('CASE: ÐÐ°Ñ‡Ð°Ñ‚ÑŒ Ð¾Ð±ÑƒÑ‡ÐµÐ½Ð¸Ðµ')
  ctx.session.mode = 'start_learning'
  await ctx.scene.enter('step0')
})

myComposer.hears(['ðŸ’Ž ÐŸÐ¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ', 'ðŸ’Ž Top up balance'], async ctx => {
  console.log('CASE: ÐŸÐ¾Ð¿Ð¾Ð»Ð½Ð¸Ñ‚ÑŒ Ð±Ð°Ð»Ð°Ð½Ñ')
  ctx.session.mode = 'top_up_balance'
  await ctx.scene.enter('paymentScene')
})

myComposer.hears(['ðŸ¤‘ Ð‘Ð°Ð»Ð°Ð½Ñ', 'ðŸ¤‘ Balance'], async ctx => {
  console.log('CASE: Ð‘Ð°Ð»Ð°Ð½Ñ')
  ctx.session.mode = 'balance'
  await balanceCommand(ctx)
})

myComposer.hears(['ðŸ  Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ', 'ðŸ  Main menu'], async ctx => {
  console.log('CASE: Ð“Ð»Ð°Ð²Ð½Ð¾Ðµ Ð¼ÐµÐ½ÑŽ')
  ctx.session.mode = 'main_menu'
  await menuCommand(ctx)
})

myComposer.hears(['1ï¸âƒ£', '2ï¸âƒ£', '3ï¸âƒ£', '4ï¸âƒ£'], async ctx => {
  const text = ctx.message.text
  console.log(`CASE: ÐÐ°Ð¶Ð°Ñ‚Ð° ÐºÐ½Ð¾Ð¿ÐºÐ° ${text}`)
  const isRu = isRussian(ctx)
  const prompt = ctx.session.prompt
  const userId = ctx.from.id
  const numImages = parseInt(text[0])
  ctx.session.mode = 'text_to_image'
  const generate = async (num: number) => {
    if (ctx.session.mode === 'neuro_photo') {
      await generateNeuroImage(
        prompt,
        ctx.session.userModel.model_url,
        num,
        userId,
        ctx
      )
    } else {
      await generateTextToImage(
        prompt,
        ctx.session.selectedModel || '',
        num,
        userId,
        isRu,
        ctx
      )
    }
  }

  if (numImages >= 1 && numImages <= 4) {
    await generate(numImages)
  } else {
    await ctx.reply('ÐÐµÐ¸Ð·Ð²ÐµÑÑ‚Ð½Ð°Ñ ÐºÐ½Ð¾Ð¿ÐºÐ°')
  }
})

myComposer.hears(['â¬†ï¸ Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚', 'â¬†ï¸ Improve prompt'], async ctx => {
  console.log('CASE: Ð£Ð»ÑƒÑ‡ÑˆÐ¸Ñ‚ÑŒ Ð¿Ñ€Ð¾Ð¼Ð¿Ñ‚')

  await ctx.scene.enter('improvePromptWizard')
})

myComposer.hears(['ðŸ“ Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€', 'ðŸ“ Change size'], async ctx => {
  console.log('CASE: Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€')

  await ctx.scene.enter('sizeWizard')
})

myComposer.hears(
  [
    '21:9',
    '16:9',
    '3:2',
    '4:3',
    '5:4',
    '1:1',
    '4:5',
    '3:4',
    '2:3',
    '9:16',
    '9:21',
  ],
  async ctx => {
    console.log('CASE: Ð˜Ð·Ð¼ÐµÐ½Ð¸Ñ‚ÑŒ Ñ€Ð°Ð·Ð¼ÐµÑ€')
    const size = ctx.message.text
    await handleSizeSelection(ctx, size)
  }
)

myComposer.hears(['ðŸŽ¥ Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² Ð²Ð¸Ð´ÐµÐ¾', 'ðŸŽ¥ Image to Video'], async ctx => {
  console.log('CASE: Ð˜Ð·Ð¾Ð±Ñ€Ð°Ð¶ÐµÐ½Ð¸Ðµ Ð² Ð²Ð¸Ð´ÐµÐ¾')
  ctx.session.mode = 'image_to_video'
  await ctx.scene.enter('imageToVideoWizard')
})

myComposer.hears(
  ['ðŸŽ¥ Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾', 'ðŸŽ¥ Generate new video'],
  async ctx => {
    console.log('CASE: Ð¡Ð³ÐµÐ½ÐµÑ€Ð¸Ñ€Ð¾Ð²Ð°Ñ‚ÑŒ Ð½Ð¾Ð²Ð¾Ðµ Ð²Ð¸Ð´ÐµÐ¾')
    ctx.session.mode = 'text_to_video'
    await ctx.scene.enter('textToVideoWizard')
  }
)

export default myComposer
